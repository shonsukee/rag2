# ãƒ¦ãƒ¼ã‚¶ãŒå±¥æ­´ã®è¿½åŠ ã‚’é¸æŠã§ãã‚‹
import os
from dotenv import load_dotenv
from openai import OpenAI
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.pinecone import PineconeVectorStore
from pinecone import Pinecone
import streamlit as st
import numpy as np
from store_llama import insert_query_response_to_db
from repo import save_doc_to_text, mov_saved_doc

API_KEY_PROMPT="API name to be modified"
SOURCE_INDEX_NAME="switchbot-llama"
HISTORY_INDEX_NAME="revision-history-v1"

# ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰
load_dotenv()

client = OpenAI()
# Pineconeã®åˆæœŸåŒ–
pc = Pinecone(api_key=os.environ.get("PINECONE_IOT_API_KEY"))

def initialize_db(index_name = SOURCE_INDEX_NAME):
	# Pineconeã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¨­å®š
	pinecone_index = pc.Index(index_name)

	# PineconeVectorStoreã®è¨­å®š
	vector_store = PineconeVectorStore(pinecone_index)
	index = VectorStoreIndex.from_vector_store(vector_store=vector_store)

	retriever = index.as_retriever(search_kwargs={"k": 5})
	return retriever

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«é–¢é€£ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°
def query_index(user_query):
    context = ""
    similarities = []
    i = 0
    retriever = initialize_db()
    context_nodes = retriever.retrieve(user_query.split('```python\n')[1])
    for node in context_nodes:
        if node.score >= 0.01:
            i += 1
            context += f"""
                Context number {i} (score: {node.score}):
                {node.text}
            """
            similarities.append(node.score)
    similarity = np.mean(similarities)

    combined_query = \
        f"""### Instruction
        You are an API-specific AI assistant, use the following pieces of context to answer the requirement at the end. If you don't know the answer, just say that you don't know, can I help with anything else, don't try to make up an answer.

        ### Context
        {context}

        ### Input Data
        {user_query}

        ### Output Indicator
        First, you read the code and the context corresponding to the previous specification in turn and identify any new information or changes. **Follow the contextual information when making modifications. Be carefulAuthorization.** Make all modifications in the function except for imports. Keep the answer as concise as possible. Output only code.
    """

    chatgpt_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an API-specific AI assistant, use the following pieces of context to answer the requirement at the end. If you don't know the answer, just say that you don't know, can I help with anything else, don't try to make up an answer."},
            {"role": "user", "content": combined_query}
        ]
    )
    return chatgpt_response.choices[0].message.content, context, similarity

def click_button(idx):
    st.session_state.messages[idx]["flag"] = True
    st.rerun()

def add_history(prompt, response, key):
    # å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ä¿å­˜ã™ã‚‹
    prompt_lists = prompt.split('## ')
    api_lists = [item.split('\n') for item in prompt_lists]

    api_list = list(filter(lambda x: x[0]==API_KEY_PROMPT, api_lists))
    api_name = ""
    if api_list:
        api_name = api_list[0][1].split()[0].lower()

    if api_name == "":
        return

    save_doc_to_text(query=prompt, response=response, api_name=api_name)

    # å±¥æ­´ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã™ã‚‹
    input_dir = f"../history/{api_name}"
    insert_query_response_to_db(index_name=HISTORY_INDEX_NAME, input_dir=input_dir, chunk_size=1536, chunk_over_lap=0)

    # å±¥æ­´ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
    move_dir = f"../history/{api_name}"
    mov_saved_doc(source_path=move_dir, api_name=api_name)

    # ãƒœã‚¿ãƒ³ã®ç„¡åŠ¹åŒ–
    click_button(key)

def main():
    # streamlitã§GUIè¡¨ç¤º
    st.title("API search assistant")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    prompt = ""
    # éå»ã®çµæœã‚’è¡¨ç¤º
    for i, message in enumerate(st.session_state["messages"]):
        with st.chat_message(message["role"]):
            if message["role"] == "user":
                prompt = message["content"]
                st.write(message["content"])

            elif message["role"] == "assistant":
                st.write("score: ", message['similarity'])
                st.write(message["content"])

                if not message["flag"]:
                    if st.button('ğŸ‘', key=f"button_{i}"):
                        with st.spinner('inserting...'):
                            add_history(prompt=prompt, response=message["content"], key=i)
                else:
                    st.write("Added data.")

                with st.expander("detail"):
                    st.write(message["expandar_content"])

    if 'button' not in st.session_state:
        st.session_state.button = False

    # ç¾åœ¨ã®å›ç­”ã‚’è¡¨ç¤º
    if prompt := st.chat_input("Please enter what you want to search for:"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        with st.spinner('searching...'):
            response, relevant_info, similarity = query_index(prompt)

        st.session_state.messages.append({"role": "assistant", "content": response, "expandar_content": relevant_info, "similarity": similarity, "flag": False})
        with st.chat_message("assistant"):
            st.write("score: ", similarity)
            st.write(response)

            key_cnt = len(st.session_state["messages"]) - 1
            if not st.session_state.messages[-1]["flag"]:
                if st.button('ğŸ‘', key=f"button_{key_cnt}"):
                    with st.spinner('inserting...'):
                        add_history(prompt=prompt, response=response, key=key_cnt)
            if response != "Relevant information not found.":
                with st.expander("detail"):
                    st.write(relevant_info)

if __name__ == "__main__":
    main()